
# üìù Publications 
-----
<img style="float: left; margin:5px 10px" src="images/papers/eccv-24-actionvos.png" width="210" height="160">
### ActionVOS: Actions as Prompts for Video Object Segmentation
<p style="line-height:1.0">
<font size="2">
Liangyang Ouyang, <strong>Ruicong Liu</strong>, Yifei Huang, Ryosuke Furuta, Yoichi Sato <br />
European Conference on Computer Vision (<strong>ECCV</strong>), 2024<br />
<a href="https://arxiv.org/pdf/2407.07402">Paper</a> | 
<a href="https://github.com/ut-vision/ActionVOS">Code</a>
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/eccv-24-mae.png" width="210" height="160">
### Masked Video and Body-worn IMU Autoencoder for Egocentric Action Recognition
<p style="line-height:1.0">
<font size="2">
Mingfang Zhang, Yifei Huang, <strong>Ruicong Liu</strong>, Yoichi Sato <br />
European Conference on Computer Vision (<strong>ECCV</strong>), 2024 <br /> 
<a href="https://arxiv.org/pdf/2407.06628">Paper</a> 
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/cvpr-24-s2dhand.png" width="210" height="160">
### Single-to-Dual-View Adaptation for Egocentric 3D Hand Pose Estimation
<p style="line-height:1.0">
<font size="2">
<strong>Ruicong Liu</strong>, Takehiko Ohkawa, Mingfang Zhang, Yoichi Sato <br />
IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024 <br /> 
<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Single-to-Dual-View_Adaptation_for_Egocentric_3D_Hand_Pose_Estimation_CVPR_2024_paper.pdf">Paper</a> | 
<a href="https://www.youtube.com/watch?v=EzlmIre1PCY&t=25s">Video</a> |
<a href="https://github.com/ut-vision/S2DHand">Code</a>
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/tpami-24-pnpga+" width="210" height="160">
### PnP-GA+: Plug-and-Play Domain Adaptation for Gaze Estimation using Model Variants
<p style="line-height:1.0">
<font size="2">
<strong>Ruicong Liu</strong>, Yunfei Liu, Haofei Wang, Feng Lu <br />
IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024 <br /> 
<a href="https://ieeexplore.ieee.org/abstract/document/10378867/">Paper</a>
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/aaai-24-uvagaze.png" width="210" height="160">
### UVAGaze: Unsupervised 1-to-2 Views Adaptation for Gaze Estimation
<p style="line-height:1.0">
<font size="2">
<strong>Ruicong Liu</strong>, Feng Lu <br />
AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024 <br /> 
<a href="https://arxiv.org/pdf/2312.15644">Paper</a> | 
<a href="https://github.com/MickeyLLG/UVAGaze">Code</a>
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/iccv-21.png" width="210" height="160">
### Generalizing gaze estimation with outlier-guided collaborative adaptation
<p style="line-height:1.0">
<font size="2">
Yunfei Liu*, <strong>Ruicong Liu*</strong>, Haofei Wang, Feng Lu <br />
IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2021 <br /> 
<a href="http://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Generalizing_Gaze_Estimation_With_Outlier-Guided_Collaborative_Adaptation_ICCV_2021_paper.pdf">Paper</a> | 
<a href="https://github.com/DreamtaleCore/PnP-GA">Code</a>
<br />
</font>
</p>
<br />

<img style="float: left; margin:5px 10px" src="images/papers/arxiv-22-jitter.png" width="210" height="160">
### Jitter does matter: Adapting gaze estimation to new domains
<p style="line-height:1.0">
<font size="2">
<strong>Ruicong Liu</strong>, Yiwei Bao, Mingjie Xu, Haofei Wang, Yunfei Liu, Feng Lu <br />
arXiv preprint arXiv:2210.02082 <br /> 
<a href="https://arxiv.org/pdf/2210.02082">Paper</a> 
<br />
</font>
</p>
<br />

